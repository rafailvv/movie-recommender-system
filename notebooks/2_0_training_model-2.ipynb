{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hg7z6x0gwY7H",
    "outputId": "467f0f19-acf0-4781-a109-c24ac77c6f08"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu118)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.16.0+cu118)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
      "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.23.5)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.11.17)\n",
      "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.functional import mse_loss\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "RANDOM_SEED =42\n"
   ],
   "metadata": {
    "id": "UTd87jg4VUjU"
   },
   "execution_count": 251,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Load data\n",
    "df = pd.read_csv('merged.csv')\n",
    "\n",
    "# Encode categorical variables\n",
    "user_encoder = LabelEncoder()\n",
    "movie_encoder = LabelEncoder()\n",
    "occupation_encoder = LabelEncoder()\n",
    "zip_code_encoder = LabelEncoder()\n",
    "release_year_encoder = LabelEncoder()\n",
    "\n",
    "df['zip_code'] = zip_code_encoder.fit_transform(df['zip_code'])\n",
    "df['release_year'] = release_year_encoder.fit_transform(df['release_year'])\n",
    "df['occupation'] = occupation_encoder.fit_transform(df['occupation'])\n",
    "\n",
    "# One-hot encoding for gender\n",
    "df = pd.get_dummies(df, columns=['gender'])\n",
    "\n",
    "# Normalize age\n",
    "df['age'] = (df['age'] - df['age'].mean()) / df['age'].std()\n",
    "\n",
    "# Process genres\n",
    "all_genres = [\"unknown\", \"Action\", \"Adventure\", \"Animation\", \"Children's\",\n",
    "          \"Comedy\", \"Crime\", \"Documentary\", \"Drama\", \"Fantasy\",\n",
    "          \"Film-Noir\", \"Horror\", \"Musical\", \"Mystery\", \"Romance\",\n",
    "          \"Sci-Fi\", \"Thriller\", \"War\", \"Western\"]\n",
    "\n",
    "# Train-test split\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=RANDOM_SEED)"
   ],
   "metadata": {
    "id": "DfvhfiobVhaf"
   },
   "execution_count": 266,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class MovieDataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.ages = torch.tensor(dataframe['age'].values, dtype=torch.float32)\n",
    "        self.occupations = torch.tensor(dataframe['occupation'].values)\n",
    "        self.genders = torch.tensor(dataframe[['gender_F', 'gender_M']].values, dtype=torch.float32)\n",
    "        self.genre_features = torch.tensor(dataframe[list(all_genres)].values, dtype=torch.float32)\n",
    "        self.zip_codes = torch.tensor(dataframe['zip_code'].values)\n",
    "        self.release_years = torch.tensor(dataframe['release_year'].values)\n",
    "        self.ratings = torch.tensor(dataframe['rating'].values, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.ratings)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.zip_codes[idx], self.release_years[idx],\n",
    "                self.ages[idx], self.occupations[idx],\n",
    "                self.genders[idx], self.genre_features[idx]), self.ratings[idx]\n",
    "\n",
    "train_dataset = MovieDataset(train_df)\n",
    "test_dataset = MovieDataset(test_df)\n"
   ],
   "metadata": {
    "id": "OjeKbAK8Vixw"
   },
   "execution_count": 253,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class RecommenderNet(nn.Module):\n",
    "    def __init__(self, num_zip_codes, num_release_years, num_occupations, num_genres, embedding_size):\n",
    "        super(RecommenderNet, self).__init__()\n",
    "        # Embeddings\n",
    "        self.zip_code_embedding = nn.Embedding(num_zip_codes, embedding_size)\n",
    "        self.release_year_embedding = nn.Embedding(num_release_years, embedding_size)\n",
    "        self.occupation_embedding = nn.Embedding(num_occupations, embedding_size)\n",
    "\n",
    "        # Linear layers for age and gender\n",
    "        self.age_lin = nn.Linear(1, embedding_size)\n",
    "        self.gender_lin = nn.Linear(2, embedding_size)\n",
    "\n",
    "        # Fully connected layers\n",
    "        self.fc1 = nn.Linear(embedding_size * 5 + num_genres, 128)\n",
    "        self.bn1 = nn.BatchNorm1d(128)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.fc3 = nn.Linear(64, 1)\n",
    "\n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "\n",
    "    def forward(self, zip_codes, release_years, ages, occupations, genders, genre_features):\n",
    "        zip_code_embedding = self.zip_code_embedding(zip_codes)\n",
    "        release_year_embedding = self.release_year_embedding(release_years)\n",
    "        occupation_embedding = self.occupation_embedding(occupations)\n",
    "        age_embedding = self.age_lin(ages.unsqueeze(1))\n",
    "        gender_embedding = self.gender_lin(genders)\n",
    "\n",
    "        x = torch.cat([zip_code_embedding, release_year_embedding, occupation_embedding,\n",
    "                       age_embedding, gender_embedding, genre_features], dim=1)\n",
    "        x = nn.ReLU()(self.bn1(self.fc1(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = nn.ReLU()(self.bn2(self.fc2(x)))\n",
    "        x = torch.sigmoid(self.fc3(x))\n",
    "        return x.squeeze()"
   ],
   "metadata": {
    "id": "mmLbNC8ZVkTA"
   },
   "execution_count": 254,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "embedding_size = 50\n",
    "num_zip_codes = df['zip_code'].nunique()\n",
    "num_release_years = df['release_year'].nunique()\n",
    "num_movies = df['film_id'].nunique()\n",
    "num_occupations = df['occupation'].nunique()\n",
    "num_generes = len(all_genres)\n",
    "model = RecommenderNet(num_zip_codes, num_release_years, num_occupations, num_generes, embedding_size)"
   ],
   "metadata": {
    "id": "5XJq5jCHVrbs"
   },
   "execution_count": 275,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Hyperparameters\n",
    "learning_rate = 0.001\n",
    "epochs = 50\n",
    "batch_size = 32\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# DataLoader\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "\n",
    "# Best model initialization\n",
    "best_loss = float('inf')\n",
    "best_model_path = 'best.pth'\n",
    "\n",
    "# Training loop\n",
    "model.train()\n",
    "for epoch in tqdm(range(epochs), desc='Epochs'):\n",
    "    running_loss = 0.0\n",
    "    for (zip_codes, release_years, ages, occupations, genders, genre_features), ratings in train_loader:\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(zip_codes, release_years, ages, occupations, genders, genre_features)\n",
    "\n",
    "        loss = criterion(outputs * 5, ratings)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Calculate average loss for the epoch\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    tqdm.write(f'Epoch {epoch+1}/{epochs}, Loss: {epoch_loss}')\n",
    "\n",
    "    # Save the best model\n",
    "    if epoch_loss < best_loss:\n",
    "        best_loss = epoch_loss\n",
    "        torch.save(model.state_dict(), best_model_path)\n",
    "\n",
    "print(f'Training complete. Best model saved to {best_model_path}')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a5avdTiRVt29",
    "outputId": "aaff3803-8f40-41f8-de8f-bdd9ca52cafc"
   },
   "execution_count": 276,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epochs:   2%|▏         | 1/50 [00:11<09:32, 11.68s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50, Loss: 1.13294924390316\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epochs:   4%|▍         | 2/50 [00:22<09:04, 11.35s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 2/50, Loss: 1.0553961817264557\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epochs:   6%|▌         | 3/50 [00:33<08:37, 11.01s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 3/50, Loss: 1.0289430654883385\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epochs:   8%|▊         | 4/50 [00:43<08:10, 10.67s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 4/50, Loss: 1.0152815279006957\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epochs:  10%|█         | 5/50 [00:54<08:06, 10.80s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 5/50, Loss: 0.9993054326534271\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epochs:  12%|█▏        | 6/50 [01:05<07:58, 10.88s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 6/50, Loss: 0.9900121225118637\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epochs:  14%|█▍        | 7/50 [01:16<07:52, 10.98s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 7/50, Loss: 0.979590152490139\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epochs:  16%|█▌        | 8/50 [01:27<07:36, 10.86s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 8/50, Loss: 0.9704590464472771\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epochs:  18%|█▊        | 9/50 [01:38<07:24, 10.85s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 9/50, Loss: 0.9615266884088516\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epochs:  20%|██        | 10/50 [01:49<07:16, 10.91s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 10/50, Loss: 0.9537577672600747\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epochs:  22%|██▏       | 11/50 [02:00<07:07, 10.96s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 11/50, Loss: 0.9458072616577149\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epochs:  24%|██▍       | 12/50 [02:11<06:55, 10.94s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 12/50, Loss: 0.9366094302296638\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epochs:  26%|██▌       | 13/50 [02:21<06:32, 10.62s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 13/50, Loss: 0.9313637337803841\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epochs:  28%|██▊       | 14/50 [02:32<06:26, 10.74s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 14/50, Loss: 0.9232876451969146\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epochs:  30%|███       | 15/50 [02:43<06:19, 10.83s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 15/50, Loss: 0.913116271173954\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epochs:  32%|███▏      | 16/50 [02:54<06:10, 10.90s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 16/50, Loss: 0.90924215914011\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epochs:  34%|███▍      | 17/50 [03:04<05:51, 10.66s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 17/50, Loss: 0.9032498761057853\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epochs:  36%|███▌      | 18/50 [03:15<05:42, 10.71s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 18/50, Loss: 0.898997637963295\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epochs:  38%|███▊      | 19/50 [03:26<05:36, 10.86s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 19/50, Loss: 0.8894464609503746\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epochs:  40%|████      | 20/50 [03:37<05:29, 10.98s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 20/50, Loss: 0.8901925159573555\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epochs:  42%|████▏     | 21/50 [03:48<05:20, 11.06s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 21/50, Loss: 0.8810836313009263\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epochs:  44%|████▍     | 22/50 [03:58<04:59, 10.71s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 22/50, Loss: 0.874543854033947\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epochs:  46%|████▌     | 23/50 [04:10<04:53, 10.87s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 23/50, Loss: 0.8736166504383087\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epochs:  48%|████▊     | 24/50 [04:21<04:44, 10.92s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 24/50, Loss: 0.8733540386199952\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epochs:  50%|█████     | 25/50 [04:32<04:33, 10.95s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 25/50, Loss: 0.8665073402881622\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epochs:  52%|█████▏    | 26/50 [04:42<04:21, 10.90s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 26/50, Loss: 0.8612413920164108\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epochs:  54%|█████▍    | 27/50 [04:53<04:08, 10.80s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 27/50, Loss: 0.8590361646652221\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epochs:  56%|█████▌    | 28/50 [05:04<04:01, 10.99s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 28/50, Loss: 0.8552828449130059\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epochs:  58%|█████▊    | 29/50 [05:16<03:55, 11.20s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 29/50, Loss: 0.849537077987194\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epochs:  60%|██████    | 30/50 [05:27<03:44, 11.23s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 30/50, Loss: 0.8473216050744057\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epochs:  62%|██████▏   | 31/50 [05:38<03:29, 11.04s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 31/50, Loss: 0.8422981479167938\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epochs:  64%|██████▍   | 32/50 [05:48<03:14, 10.82s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 32/50, Loss: 0.8383844039440155\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epochs:  66%|██████▌   | 33/50 [05:59<03:05, 10.92s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 33/50, Loss: 0.836379934489727\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epochs:  68%|██████▊   | 34/50 [06:11<02:55, 10.98s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 34/50, Loss: 0.8322285580158234\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epochs:  70%|███████   | 35/50 [06:22<02:45, 11.02s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 35/50, Loss: 0.8307256586670876\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epochs:  72%|███████▏  | 36/50 [06:32<02:30, 10.72s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 36/50, Loss: 0.8298491563796997\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epochs:  74%|███████▍  | 37/50 [06:43<02:19, 10.76s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 37/50, Loss: 0.8274852422237396\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epochs:  76%|███████▌  | 38/50 [06:54<02:10, 10.86s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 38/50, Loss: 0.8248467433035374\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epochs:  78%|███████▊  | 39/50 [07:05<02:00, 10.92s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 39/50, Loss: 0.8200993158578873\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epochs:  80%|████████  | 40/50 [07:15<01:48, 10.84s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 40/50, Loss: 0.8169411064982415\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epochs:  82%|████████▏ | 41/50 [07:26<01:35, 10.66s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 41/50, Loss: 0.8145286303758621\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epochs:  84%|████████▍ | 42/50 [07:37<01:26, 10.79s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 42/50, Loss: 0.814997122490406\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epochs:  86%|████████▌ | 43/50 [07:48<01:16, 10.86s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 43/50, Loss: 0.8089045756101608\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epochs:  88%|████████▊ | 44/50 [07:59<01:05, 10.90s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 44/50, Loss: 0.8092224455595016\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epochs:  90%|█████████ | 45/50 [08:09<00:53, 10.61s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 45/50, Loss: 0.8094413524627686\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epochs:  92%|█████████▏| 46/50 [08:19<00:42, 10.69s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 46/50, Loss: 0.8043764558315277\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epochs:  94%|█████████▍| 47/50 [08:31<00:32, 10.85s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 47/50, Loss: 0.802017207801342\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epochs:  96%|█████████▌| 48/50 [08:42<00:21, 10.93s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 48/50, Loss: 0.8003044772267341\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epochs:  98%|█████████▊| 49/50 [08:53<00:10, 10.94s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 49/50, Loss: 0.7984246416091919\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Epochs: 100%|██████████| 50/50 [09:03<00:00, 10.87s/it]"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 50/50, Loss: 0.7972482315540314\n",
      "Training complete. Best model saved to best.pth\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "def evaluate_model(model, test_loader):\n",
    "    model.eval()\n",
    "    mse = 0\n",
    "    with torch.no_grad():\n",
    "        for (zip_codes, release_years, ages, occupations, genders, genre_features), ratings in test_loader:\n",
    "            outputs =  model(zip_codes, release_years, ages, occupations, genders,genre_features) * 5\n",
    "            mse += mse_loss(outputs, ratings)\n",
    "            break\n",
    "    mse = mse / len(test_loader)\n",
    "    return np.sqrt(mse)\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "rmse = evaluate_model(model, test_loader)\n",
    "print(f'RMSE on test set: {rmse}')\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ife9Fo7JV6YS",
    "outputId": "9aa69200-59d2-45a0-a23e-fe2ff713e83d"
   },
   "execution_count": 289,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "tensor([62, 58, 67, 65, 68, 61, 66, 69, 11, 68, 62, 69, 68, 70, 58, 40, 54, 69,\n",
      "        42, 66, 13, 26, 67, 69, 65, 67, 69, 68, 52, 49, 68, 69])\n",
      "RMSE on test set: 0.039171721786260605\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "def recommend_movies(model, age, gender, occupation, zip_code, num_recommendations=5):\n",
    "    # Convert inputs using encoders and normalization\n",
    "    encoded_occupation = occupation_encoder.transform([occupation])[0]\n",
    "    encoded_zip_code = zip_code_encoder.transform([zip_code])[0]\n",
    "    normalized_age = (age - df['age'].mean()) / df['age'].std()\n",
    "\n",
    "    # Prepare gender input\n",
    "    gender_input = np.array([[1, 0] if gender == 'F' else [0, 1]])\n",
    "\n",
    "    # Prepare inputs for all movies\n",
    "    movie_ids = np.arange(num_movies)\n",
    "    zip_codes = np.full_like(movie_ids, encoded_zip_code)\n",
    "    ages = np.full_like(movie_ids, normalized_age, dtype=np.float32)\n",
    "    occupations = np.full_like(movie_ids, encoded_occupation)\n",
    "    genders = np.tile(gender_input, (num_movies, 1))\n",
    "\n",
    "    # Convert to tensors\n",
    "    zip_codes_tensor = torch.tensor(zip_codes)\n",
    "    ages_tensor = torch.tensor(ages, dtype=torch.float32)\n",
    "    occupations_tensor = torch.tensor(occupations)\n",
    "    genders_tensor = torch.tensor(genders, dtype=torch.float32)\n",
    "\n",
    "    # Generate predictions for all movies\n",
    "    model.eval()\n",
    "    predictions = np.zeros(num_movies)\n",
    "    with torch.no_grad():\n",
    "        for i in range(0, num_movies, batch_size):\n",
    "            if i + batch_size > num_movies:\n",
    "              i = num_movies - batch_size\n",
    "            genre_features = torch.tensor(df.loc[:, list(all_genres)].values, dtype=torch.float32)\n",
    "            release_years = torch.tensor(df['release_year'].tolist())\n",
    "            batch_predictions = model(zip_codes_tensor[i:i+batch_size],\n",
    "                                      release_years[i:i+batch_size],\n",
    "                                      ages_tensor[i:i+batch_size],\n",
    "                                      occupations_tensor[i:i+batch_size],\n",
    "                                      genders_tensor[i:i+batch_size],\n",
    "                                      genre_features[i:i+batch_size])\n",
    "            predictions[i:i+batch_size] = batch_predictions.numpy()\n",
    "\n",
    "    # Sort by predicted rating\n",
    "    sorted_indices = np.argsort(predictions)[::-1]\n",
    "    top_movie_ids = sorted_indices[:num_recommendations]\n",
    "    top_movie_ratings = predictions[top_movie_ids]\n",
    "\n",
    "    # Convert movie IDs back to movie names and pair with their ratings\n",
    "    movies_data = []\n",
    "    for movie_id, rating in zip(top_movie_ids, top_movie_ratings * 5):\n",
    "        movie_title = df[df['film_id'] == movie_id]['title'].iloc[0]\n",
    "        movies_data.append({\"id\": movie_id, \"title\": movie_title, \"rating\": rating})\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    recommended_movies_df = pd.DataFrame(movies_data)\n",
    "    recommended_movies_df.index = range(1, len(recommended_movies_df) + 1)\n",
    "    return recommended_movies_df"
   ],
   "metadata": {
    "id": "HQ3zYJVbWB9n"
   },
   "execution_count": 339,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Example user details\n",
    "age = 20\n",
    "gender = 'F'\n",
    "occupation = 'writer'\n",
    "zip_code = '12345'\n",
    "\n",
    "# Number of recommendations\n",
    "num_recommendations = 10\n",
    "\n",
    "# Get recommendations\n",
    "top_movies_df = recommend_movies(model, age, gender, occupation, zip_code, num_recommendations)\n",
    "print(top_movies_df)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nHiaN6Dffk-K",
    "outputId": "cc9e89da-d739-469b-9384-dad891bd7b51"
   },
   "execution_count": 351,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "      id                                      title    rating\n",
      "1    327                            Cop Land (1997)  4.966209\n",
      "2    203                          Unforgiven (1992)  4.966209\n",
      "3    881                         Money Talks (1997)  4.961248\n",
      "4    566            Clear and Present Danger (1994)  4.961248\n",
      "5   1614            Reluctant Debutante, The (1958)  4.961248\n",
      "6    212  Unbearable Lightness of Being, The (1988)  4.961248\n",
      "7   1251                      A Chef in Love (1996)  4.961248\n",
      "8    344                        Apostle, The (1997)  4.961248\n",
      "9    368                            Bio-Dome (1996)  4.961243\n",
      "10   609                 Father of the Bride (1950)  4.961243\n"
     ]
    }
   ]
  }
 ]
}
